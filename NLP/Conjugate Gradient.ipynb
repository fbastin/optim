{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme du gradient conjugué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résolvez\n",
    "$$\n",
    "\\min_x f(x) = \\frac{1}{2} x^T A x + b^T x + a\n",
    "$$\n",
    "où $A \\succ 0$. En posant $\\nabla f(x) = 0$, c'est équivalent à résoudre le système linéaire $Ax = -b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons la fonction quadratique associée au programme précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x -> 0.5*dot(x,A*x)+dot(b,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un exemple simple\n",
    "\n",
    "Adapté de https://www.rose-hulman.edu/~bryan/lottamath/congrad.pdf\n",
    "\n",
    "Soit\n",
    "$$\n",
    "A =\n",
    "\\begin{pmatrix}\n",
    "3 & 1 & 0 \\\\\n",
    "1 & 2 & 2 \\\\\n",
    "0 & 2 & 4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Considérons la fonction à minimiser\n",
    "$$\n",
    "f(x) = \\frac{1}{2} x^TAx,\n",
    "$$\n",
    "et supposons que nous avons déjà calculé\n",
    "\\begin{align*}\n",
    "d_0 &= (1, 0, 0)\\\\\n",
    "d_1 & = (1, −3, 0)\\\\\n",
    "d_2 &= (−2, 6, −5).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que $d_0$, $d_1$ et $d_2$ sont $A$-conjugés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [ 3.0 1 0 ; 1 2 2 ; 0 2 4]\n",
    "d0 = [ 1.0 0 0 ]'\n",
    "d1 = [ 1.0 -3.0 0.0 ]'\n",
    "d2 = [ -2.0 6.0 -5.0]'\n",
    "\n",
    "println(\"$(dot(d0, A*d1)) $(dot(d0, A*d2)) $(dot(d1, A*d2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que les valeurs propres de $A$ sont positif, et donc que le problème est convexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons comme solution initiale $x_0 = (1, 2, 3)$. Calculons $x_1$, $x_2$ et $x_3$ en utilisant l'algorithme du gradient conjugué. $x_3$ est-il optimal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nous avons\n",
    "$$\n",
    "\\nabla f(x) = Ax\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons la fonction objectif comme suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x -> dot(x,A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons calculer $\\alpha_k$, $k = 0,1,2$, en résolvant\n",
    "$$\n",
    "\\min_{\\alpha} f(x_k + \\alpha d_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'obtenir $\\alpha_0$, nous devons minimiser\n",
    "\\begin{align*}\n",
    "f(x_0 + \\alpha d_0) &= \\frac{1}{2}\n",
    "\\left(\\begin{pmatrix} 1 & 2 & 3\\end{pmatrix} + \\alpha \\begin{pmatrix} 1 & 0 & 0\\end{pmatrix} \\right)\n",
    "\\begin{pmatrix}\n",
    "3 & 1 & 0 \\\\\n",
    "1 & 2 & 2 \\\\\n",
    "0 & 2 & 4\n",
    "\\end{pmatrix}\n",
    "\\left(\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} + \\alpha \\begin{pmatrix} 1 \\\\0 \\\\0 \\end{pmatrix} \\right)\n",
    "\\\\\n",
    "& = \\frac{1}{2}\\begin{pmatrix} 1 + \\alpha & 2 & 3 \\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "3 & 1 & 0 \\\\\n",
    "1 & 2 & 2 \\\\\n",
    "0 & 2 & 4\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} 1 + \\alpha \\\\ 2 \\\\ 3 \\end{pmatrix}\\\\\n",
    "& = \\frac{1}{2}\\begin{pmatrix} 1 + \\alpha & 2 & 3 \\end{pmatrix}\n",
    "\\begin{pmatrix} 5+3\\alpha \\\\ 11+\\alpha \\\\ 16 \\end{pmatrix}\\\\\n",
    "& = \\frac{1}{2}\n",
    "((1 + \\alpha)(5+3\\alpha) + 22+2\\alpha + 48 ) \\\\\n",
    "& = \\frac{1}{2}\n",
    "( 3\\alpha^2 + 8\\alpha + 5 + 70 + 2\\alpha ) \\\\\n",
    "& = \\frac{3}{2}\\alpha^2 + 5\\alpha+\\frac{75}{2}\n",
    "\\end{align*}\n",
    "par rapport à $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons l'obtenir en cherchant le zéro de la dérivée par rapport à $\\alpha$, c'est-à-dire\n",
    "$$\n",
    "\\frac{d}{d\\alpha} f(x+\\alpha d) = 0,\n",
    "$$\n",
    "ou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d^T \\nabla f(x+\\alpha d) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dès lors, nous devons avoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "3\\alpha + 5 = 0\n",
    "$$\n",
    "Ainsi,\n",
    "$$\n",
    "\\alpha_{0} = -\\frac{5}{3}\n",
    "$$\n",
    "$$\n",
    "x_1 = x_0 - \\frac{5}{3} d_0 = \\begin{pmatrix} -\\frac{2}{3} \\\\ 2 \\\\ 3  \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi directement calculer $\\alpha_0$ comme\n",
    "$$\n",
    "\\alpha_0 = - \\frac{d_0^T\\nabla f(x_0)}{d_0^TAd_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [1 ; 2 ; 3.0]\n",
    "∇f = x -> A*x\n",
    "d0 = [1 ; 0 ; 0]\n",
    "α0 = -dot(d0,∇f(x0))/dot(d0,A*d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons le nouvel itéré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x0+α0*d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une recherche linéaire à partir de $x_1$ dans la direction $d_1$ exige de minimiser\n",
    "\\begin{align*}\n",
    "f(x_1 + \\alpha d_1) & = \\left(\\begin{pmatrix} -\\frac{2}{3} & 2 & 3 \\end{pmatrix} + \\alpha_1\\begin{pmatrix} 1 & -3 & 0 \\end{pmatrix} \\right)\\begin{pmatrix} 3 & 1 & 0 \\\\\n",
    "1 & 2 & 2 \\\\\n",
    "0 & 2 & 4 \\end{pmatrix}\\left(\\begin{pmatrix}  -\\frac{2}{3} \\\\ 2 \\\\ 3 \\end{pmatrix} +  \\alpha_1\\begin{pmatrix} 1 \\\\ -3 \\\\ 0 \\end{pmatrix} \\right) \\\\\n",
    "& =\\frac{15}{2}\\alpha^2 - 28\\alpha + \\frac{100}{3},\n",
    "\\end{align*}\n",
    "ce qui a lieu en\n",
    "$$\n",
    "\\alpha_1 = \\frac{28}{15},\n",
    "$$\n",
    "donnant\n",
    "$$\n",
    "x_2 = x_1 + \\frac{28}{15}d_1 =\n",
    "    \\begin{pmatrix}\n",
    "     \\frac{6}{5} \\\\ \\frac{-18}{5} \\\\ 3\n",
    "    \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nouvelle longueur de pas est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α1 = -dot(d1,A*x1)/dot(d1,A*d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou, sous forme de fraction, 28/15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nouvel itéré est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1+α1*d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche linéaire finale à partir de $x_2$ dans la direction $d_2$ requiert de minimiser\n",
    "$$\n",
    "f(x_2 + \\alpha d_2) = 20 \\alpha^2 - 24\\alpha + \\frac{36}{5},\n",
    "$$\n",
    "ce qui a lieu en\n",
    "$$\n",
    "\\alpha_2 = \\frac{3}{5},\n",
    "$$\n",
    "donnant\n",
    "$$\n",
    "x_3 = x_2 + \\frac{3}{5}d_2 =\n",
    "    \\begin{pmatrix}\n",
    "     0 \\\\ 0 \\\\ 0\n",
    "    \\end{pmatrix},\n",
    "$$\n",
    "ce qui est bien entendu correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similairement, nous pouvons calculer le nouveau point comme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α2 = -dot(d2,A*x2)/dot(d2,A*d2)\n",
    "x3 = x2+α2*d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_3$ est clairement optimal comme $f(x_3) = 0$ et 0 est une borne inférieure sur $f(\\cdot)$. Nous pouvons également vérifier que $x_3$ est un point critique. En effet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∇f(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une implémentation naïve\n",
    "\n",
    "Une première version de l'algorithme du gradient conjugué suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cg_quadratic(A:: Matrix, b:: Vector, x0:: Vector, trace:: Bool = false)\n",
    "    n = length(x0)\n",
    "    x = x0\n",
    "    g = b+A*x\n",
    "    d = -g\n",
    "    if (trace)\n",
    "        iter = [ x ]\n",
    "        iterg = [ norm(g) ]\n",
    "        iterd = [ norm(d) ]\n",
    "    end\n",
    "    k = 0\n",
    "    \n",
    "    for k = 1:n-1\n",
    "        Ad = A*d\n",
    "        normd = dot(d,Ad)\n",
    "        α = -dot(d,g)/normd\n",
    "        x += α*d\n",
    "        if (trace)\n",
    "            iter = [ iter; [x] ]\n",
    "            iterg = [ iterg; norm(g)]\n",
    "            iterd = [ iterd; norm(d) ]\n",
    "        end\n",
    "        g = b+A*x\n",
    "        β = dot(g,Ad)/normd\n",
    "        d = -g+β*d\n",
    "    end\n",
    "\n",
    "    normd = dot(d,A*d)\n",
    "    α = -dot(d,g)/normd\n",
    "    x += α*d\n",
    "    if (trace)\n",
    "        g = b+A*x # g must be equal to 0\n",
    "        iter = [ iter; [x] ]\n",
    "        iterg = [ iterg; norm(g)]\n",
    "        iterd = [ iterd; norm(d) ]\n",
    "        return x, iter, iterg, iterd\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons l'exemple simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [2 1; 1 2]\n",
    "b = [1, 0]\n",
    "A\\(-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons résoudre\n",
    "$$\n",
    "    \\min_{\\alpha} f(x) = \\frac{1}{2}x^TAx+b^Tx+c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, de manière équivalente, nous résolvons\n",
    "$$\n",
    "    c+\\min_{\\alpha} f(x) = \\frac{1}{2}x^TAx+b^Tx\n",
    "$$\n",
    "\n",
    "Appliquons l'algorithme que nous avons implémenté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_quadratic(A, b, [0, 0], true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que se passe-t-il si $A$ n'est pas définie positive? Considérons l'exemple simple suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [ 1 2 ; 2 1]\n",
    "A\\(-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_quadratic(A, b, [0, 0], true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_quadratic(A, b, [1, 1], true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solution est $x^* = (1/3, -2/3)$. $f(x^*)$ vaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f([1/3,-2/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le gradient conjugué trouve la solution du système linéaire, laquelle correspond à un point critique au premier ordre de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∇f = x -> A*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.0/3; -2.0/3]\n",
    "∇f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais ce n'est pas un minimum de la fonction! Nous pouvons en effet aisément partir de ce point et diminuer la valeur de la fonction. Construisons la fonction de calcul d'un itéré le long de la plus forte pente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step= x -> x-α*∇f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons obtenir une direction de courbure négative en prenant le vecteur propre associé à une valeur propre négative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ, u = eigen(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = u[:,1] # premier vecteur propre associé à λ = -1\n",
    "A*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquons que la norme du vecteur propre ainsi obtenu vaut 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0-norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construison un point le long de cette direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 10\n",
    "f = x -> 0.5*dot(x,A*x)+dot(b,x)\n",
    "f(step(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur de la fonction en ce point est clairement plus basse que la solution construite par l'algorithme du gradient conjugué!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1/3.0; -2/3]\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquons que l'algorithme du gradient conjugué est incapable de réduire la fonction en partant de la solution préalablement trouvée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_quadratic(A, b, x, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons incorporer un test sur $\\nabla f(x_k)$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple plus complexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500;\n",
    "m = 600;\n",
    "A = randn(n,m);\n",
    "A = A * A';  # A is now a positive semi-definite matrix\n",
    "A = A+I # A is positive definite\n",
    "b = zeros(n)\n",
    "for i = 1:n\n",
    "  b[i] = randn()\n",
    "end\n",
    "x0 = zeros(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = A\\(-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2, iter, iterg, iterd = cg_quadratic(A, b, x0, true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À nouveau, nous avons obtenu une solution au système $Ax = b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b1-b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons l'historique des normes du gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons à présent l'historique des normes de la direction de recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela fonctionne, mais devons-nous vraiment faire 500 itérations? Nous serions satisfaits si nous sommes proches de la solution. Nous pouvons mesurer le résidu du système linéaire residual of the linear system\n",
    "$$\n",
    "r = b+Ax,\n",
    "$$\n",
    "ce qui n'est rien d'autre que le gradient de la fonction objectif du problème de minimisation quadratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons inclure un test de convergence dans la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cg_quadratic_tol(A:: Matrix, b:: Vector, x0:: Vector, trace:: Bool = false, tol = 1e-8)\n",
    "    n = length(x0)\n",
    "    x = x0\n",
    "    if (trace)\n",
    "        iter = [ x ]\n",
    "    end\n",
    "    g = b+A*x\n",
    "    d = -g\n",
    "    k = 0\n",
    "    \n",
    "    tol2 = tol*tol\n",
    "\n",
    "    β = 0.0\n",
    "\n",
    "    while ((dot(g,g) > tol2) && (k < n))\n",
    "        Ad = A*d\n",
    "        normd = dot(d,Ad)\n",
    "        α = dot(g,g)/normd\n",
    "#        α = -dot(d,g)/normd\n",
    "        x += α*d\n",
    "        if (trace)\n",
    "            iter = [ iter; x ]\n",
    "        end\n",
    "        g = b+A*x\n",
    "        β = dot(g,Ad)/normd\n",
    "        d = -g+β*d\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    if (trace)\n",
    "        iter = [ iter; x ]\n",
    "        return x, iter, k\n",
    "    end\n",
    "\n",
    "    return x, k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = cg_quadratic_tol(A, b, x0, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'itérations est à présent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommes-nous proche de la solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ce qui est nettement moindre que la dimension du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient conjugué préconditionné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le nombre de conditionnement est égal à 1, nous convergeons en une itération.\n",
    "\n",
    "Rappelons que le nombre de conditionnement d'une matrice $A$ définie positive est donné par\n",
    "$$\n",
    "\\kappa(A) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}.\n",
    "$$\n",
    "$\\kappa(A) = 1$ ssi $A = \\gamma I$. Dans ce cas\n",
    "$$\n",
    "A = \\begin{pmatrix} \\gamma & 0 & \\cdots & 0 \\\\ 0 & \\gamma & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & \\gamma \\end{pmatrix}.\n",
    "$$\n",
    "Observons que $\\lambda_{\\max} = \\lambda_{\\min} = \\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème quadratique devient alors\n",
    "$$\n",
    "f(x) = \\frac{1}{2}\\gamma x^Tx + b^Tx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son gradient est\n",
    "$$\n",
    "\\nabla f(x) = \\gamma x + b.\n",
    "$$\n",
    "Il s'annule si\n",
    "$$\n",
    "x = -\\frac{b}{\\gamma}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $x_0$. L'algorithme du gradient conjugué donne comme première de recherche $d_0 = -\\nabla f(x_0) = -\\gamma x_0 - b$.\n",
    "\n",
    "Nous avons aussi\n",
    "$$\n",
    "\\alpha_0 = - \\frac{d_0^T\\nabla f(x_0)}{d_0^TAd_0} = \\frac{\\| d_0 \\|^2}{\\gamma \\| d_0 \\|^2} = \\frac{1}{\\gamma}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier itéré donne\n",
    "$$\n",
    "x_1 = x_0 + \\alpha_0 d_0 = x_0 + \\frac{1}{\\gamma} (-\\gamma x_0 - b) = -\\frac{b}{\\gamma}.\n",
    "$$\n",
    "ce qui correspond bien à la solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la matrice $A$ est diagonale et tous les éléments de la diagonale sont identiques, la direction de plus forte pente donne le minimum global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une implémentation basique d'un algorithme de gradient préconditionné suit, où $M$ est l'inverse du préconditioneur à appliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pcg_quadratic_tol(A:: Matrix, b:: Vector, x0:: Vector, M:: Matrix,\n",
    "                           trace:: Bool = false, tol = 1e-8)\n",
    "    n = length(x0)\n",
    "    x = x0\n",
    "    if (trace)\n",
    "        iter = [ x ]\n",
    "    end\n",
    "    g = b+A*x\n",
    "    v = M*g\n",
    "    d = -v\n",
    "    k = 0\n",
    "    \n",
    "    tol2 = tol*tol\n",
    "\n",
    "    β = 0.0\n",
    "\n",
    "    gv = dot(g,v)\n",
    "    while ((gv > tol2) && (k < n))\n",
    "#    while ((dot(g,g) > tol2) && (k < n))\n",
    "        Ad = A*d\n",
    "        normd = dot(d,Ad)\n",
    "        #gv = dot(g,v)\n",
    "        α = gv/normd\n",
    "        x += α*d\n",
    "        if (trace)\n",
    "            iter = [ iter; x ]\n",
    "        end\n",
    "        g += α*Ad\n",
    "        v = M*g\n",
    "        gvold = gv\n",
    "        gv = dot(g,v)\n",
    "        β = gv/gvold\n",
    "        d = -v+β*d\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    if (trace)\n",
    "        iter = [ iter; x ]\n",
    "        return x, iter, k\n",
    "    end\n",
    "\n",
    "    return x, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions tout d'abord qu'en l'absence de préconditionnement, nous obtenons les mêmes itérés.\n",
    "\n",
    "Posons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)+I\n",
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, norm(x-b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons calculer les valeurs propres et le nombre de conditionnement de la matrice $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de construire un préconditionneur simple en utilisant l'inverse de la diagonale de la matrice $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = 1 ./diag(A)\n",
    "M = Diagonal(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, dans ce cas, nous n'observons pas une amélioration du nombre de conditionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = M*A\n",
    "cond(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons une autre situation où $A$ est diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000;\n",
    "A = zeros(n,n);\n",
    "for i = 1:n\n",
    "    A[i,i] = 10*rand()\n",
    "end\n",
    "b = zeros(n)\n",
    "for i = 1:n\n",
    "  b[i] = rand()\n",
    "end\n",
    "x0 = zeros(n)\n",
    "cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solution que nous cherchons est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A\\b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans préconditionnement, nous avons la séquence d'itérés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)+I\n",
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est équivalent à la version de l'algorithme non-préconditionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = cg_quadratic_tol(A, b, x0, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, puisque $A$ est diagonal, un préconditionneur diagonal évident est $A^{-1}$ lui-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)\n",
    "for i = 1:n\n",
    "    M[i,i] = 1/A[i,i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de préconditionnement de la matrice préconditionnée est bien entendu égal à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond(M*A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La théorie prédit alors que nous convergeons en une itération avec le gradient conjugué précontionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais le cas diagonal n'est pas très intéressant, comme le système peut être résolut facilement, en traitant les variables indépendamment.\n",
    "\n",
    "Considérons à présent un autre exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = zeros(n,n)+3*I\n",
    "for i = 1:n-1\n",
    "    A[i,i+1] = 1.4\n",
    "    A[i+1,i] = 1.4\n",
    "end\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs propres de la matrice sont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice est donc bien définie positive et la solution du système est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A\\(-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme du gradient conjugué donne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = cg_quadratic_tol(A, b, x0, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons à nouveau comme précondtionneur l'inverse de la diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)\n",
    "for i = 1:n\n",
    "    M[i,i] = 1/A[i,i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons les nombres de conditionnement de la matrice avec et sans conditionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond(A), cond(M*A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le conditionnement de la matrice n'a pas changé, aussi nous ne devrions pas voir de différence lors de l'application de l'algorithme du gradient conjugué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fait, il n'y a pas d'avantage notable. Notons de plus la structure de $A^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peut-on exploiter la structure creuse des matrices? La librairie `SparseArrays` vient ici à notre secours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseArrays\n",
    "\n",
    "sparse(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons visualier que l'inversion transforme une matrice creuse en matrice dense. Ce n'est pas intéressant, même si, évidemment, nous n'avons à présent besoin que d'une itération avec l'algorithme du gradient conjugé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons l'exemple suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "A = zeros(n,n)+Diagonal([2+i*i for i=1:n])\n",
    "\n",
    "for i = 1:n-1\n",
    "    A[i,i+1] = 1\n",
    "    A[i+1,i] = 1\n",
    "end\n",
    "A[n,1] = 1\n",
    "A[1,n] = 1\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice ainsi construite est particulièrement creuse. De telles structures apparaissent des divers problèmes physiques.\n",
    "\n",
    "Nous l'avons construite de telle manière à avoir un très mauvais conditionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux de convergence prédit est très lent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "κ = cond(A)\n",
    "(sqrt(κ)-1)/(sqrt(κ)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais à nouveau, l'inverse de la matrice est dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A^(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons tout d'abord avec la matrice identité (autrement dit, nous n'appliquons pas de préconditionnement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)+I\n",
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre maximum d'itérations est atteint, pour une précision restant moyenne. En effet, si nous comparons avec la solution recherchée, nous obtenons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = A\\(-b)\n",
    "x-xopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons à nouveau de préconditionner le système avec l'inverse de la diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)\n",
    "for i = 1:n\n",
    "    M[i,i] = 1/A[i,i]\n",
    "end\n",
    "cond(A*M), cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le conditionnement de la matrice préconditionnée est cette fois-ci nettement meilleur, suggérant que $M$ est un bon préconditionneur. Essayons done l'algorithme du gradient conjugué préconditionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic_tol(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non seulement, le nombre d'itérations est nettement inférieur, mais la précision est grandement améliorée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x-xopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le préconditionnement est cependant souvent utilisé pour produire une matrice proche de $A$, mais permettant de résoudre de manière plus efficace des systèmes linéaires. La version suivante de l'algorithme du gradient conjugué préconditionné.\n",
    "\n",
    "Deux versions sont proposées, une avec une matrice régulière, une avec une matrice triangulaire inférieure, sachant que résoudre un système triangulaire est direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pcg_quadratic(A:: Matrix, b:: Vector, x0:: Vector, M:: Matrix,\n",
    "                       trace:: Bool = false, tol = 1e-8)\n",
    "    n = length(x0)\n",
    "    x = x0\n",
    "    if (trace)\n",
    "        iter = [ x ]\n",
    "    end\n",
    "    g = b+A*x\n",
    "    v = M\\g    # l'application de M se fait à présent en calculant un système linéaire plutôt qu'une multiplication matricielle.\n",
    "    d = -v\n",
    "    k = 0\n",
    "    \n",
    "    tol2 = tol*tol\n",
    "\n",
    "    β = 0.0\n",
    "\n",
    "    gv = dot(g,v)\n",
    "    while ((gv > tol2) && (k <= n))\n",
    "#    while ((dot(g,g) > tol2) && (k <= n))\n",
    "        Ad = A*d\n",
    "        normd = dot(d,Ad)\n",
    "        #gv = dot(g,v)\n",
    "        α = gv/normd\n",
    "        x += α*d\n",
    "        if (trace)\n",
    "            iter = [ iter; x ]\n",
    "        end\n",
    "        g += α*Ad\n",
    "        v = M\\g\n",
    "        gvold = gv\n",
    "        gv = dot(g,v)\n",
    "        β = gv/gvold\n",
    "        d = -v+β*d\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    if (trace)\n",
    "        iter = [ iter; x ]\n",
    "        return x, iter, k\n",
    "    end\n",
    "\n",
    "    return x, k\n",
    "end\n",
    "\n",
    "function pcg_quadratic(A:: Matrix, b:: Vector, x0:: Vector, L:: LowerTriangular,\n",
    "                       trace:: Bool = false, tol = 1e-8)\n",
    "    n = length(x0)\n",
    "    x = x0\n",
    "    if (trace)\n",
    "        iter = [ x ]\n",
    "    end\n",
    "    g = b+A*x\n",
    "    U = transpose(L)\n",
    "    v = U\\(L\\g)    # l'application de M se fait à présent en calculant un système linéaire plutôt qu'une multiplication matricielle.\n",
    "    d = -v\n",
    "    k = 0\n",
    "    \n",
    "    tol2 = tol*tol\n",
    "\n",
    "    β = 0.0\n",
    "\n",
    "    gv = dot(g,v)\n",
    "    while ((gv > tol2) && (k <= n))\n",
    "#    while ((dot(g,g) > tol2) && (k <= n))\n",
    "        Ad = A*d\n",
    "        normd = dot(d,Ad)\n",
    "        #gv = dot(g,v)\n",
    "        α = gv/normd\n",
    "        x += α*d\n",
    "        if (trace)\n",
    "            iter = [ iter; x ]\n",
    "        end\n",
    "        g += α*Ad\n",
    "        v = U\\(L\\g)\n",
    "        gvold = gv\n",
    "        gv = dot(g,v)\n",
    "        β = gv/gvold\n",
    "        d = -v+β*d\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    if (trace)\n",
    "        iter = [ iter; x ]\n",
    "        return x, iter, k\n",
    "    end\n",
    "\n",
    "    return x, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un préconditionneur populaire est la factorisation de Cholesky incomplète, qui reproduit la factorisation de Cholesky, mais en ne considérant que les positions où l'élément de la matrice initiale est non nul, avec de conserver le caractère creux (si présent), et en s'arrêtant prématurément si la matrice se révèle non définie positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ichol(A:: Matrix)\n",
    "\n",
    "    n = size(A,1)\n",
    "    C = LowerTriangular(zeros(n,n)+I)\n",
    "    \n",
    "    for k=1:n\n",
    "        C[k,k] = sqrt(A[k,k])\n",
    "        for i=(k+1):n\n",
    "            if (A[i,k] != 0)\n",
    "                C[i,k] = A[i,k]/A[k,k]    \n",
    "            end\n",
    "        end\n",
    "        for j=(k+1):n\n",
    "            for i=j:n\n",
    "                if (A[i,j] != 0)\n",
    "                    C[i,j] = A[i,j]-A[i,k]*A[j,k]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'abord avec la factorisation complète de A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = cholesky(A)\n",
    "C.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = C.L*C.U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous essayons d'appliquer l'algorithme du gradient conjugué préconditionné, nous voyons que nous convergeons en une itération, ce qui est logique vu que $M = A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Néanmoins, l'algorithme converge plus rapidement en utilisant le facteur de Cholesky directement plutôt que $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark pcg_quadratic(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark pcg_quadratic(A, b, x0, C.L, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travailler avec le facteur de Cholesky accélère grandement la résolution du système!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travaillons à présent avec la factorisation incomplète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ichol(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La factorisation reste incomplète, comme illustré ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=C*C'\n",
    "norm(M-A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons néanmoins utiliser ce facteur pour résoudre le système."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, iter, k = pcg_quadratic(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous prenons à présent 6 itérations, comme la factorisation n'a pas été conduite jusqu'au bout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark pcg_quadratic(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark pcg_quadratic(A, b, x0, C, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travailler avec la matrice sous forme plein ralentit le code en raison du nombre plus grand d'itérations, mais la version triangulaire est encore plus rapide.\n",
    "\n",
    "Mais dans tous les cas, nous sommes bien plus efficace que la version non préconditionnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = zeros(n,n)+I\n",
    "@benchmark pcg_quadratic(A, b, x0, M, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons aussi que la version proposée du gradient conjuguée, avec le préconditioneur triangulaire, est plus rapide que la résolution directe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark A\\(-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évidemment, ceci néglige le temps utlisé pour calculer le facteur. Malheureusement, le code implémenté n'est pas encore très efficace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark ichol(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une implémentation efficace ferait usage des matrices creuses et de fonctions spécifiques pour caluler $v$."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
